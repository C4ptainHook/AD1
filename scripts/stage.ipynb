{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with each table of stage (All credential need to be set up in the current directory inside the .env file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_username = os.getenv(\"DB_USERNAME\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{db_username}:{db_password}@{db_host}:{db_port}/{db_name}\"\n",
    ")\n",
    "\n",
    "table_names = ['all_steam', 'genres', 'mdn_play_time','metacritic_review','play_time_by_player','regions','time_to_beat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial extraction into the stage area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_csv(params_json):\n",
    "    params = json.loads(params_json)\n",
    "    csv_file_path = params[\"csv_file_path\"]\n",
    "    separator = params[\"separator\"]\n",
    "    columns = params[\"columns\"]\n",
    "    df = pd.read_csv(csv_file_path, sep=separator, encoding=\"utf-8\")\n",
    "    missing_columns = set(df.columns) - set(columns)\n",
    "    for col in missing_columns:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "    df = df.fillna(\"null\")\n",
    "    file_name = os.path.basename(csv_file_path)\n",
    "    df.to_csv(f\"./Datasets/Processed/{file_name}\", index=False)\n",
    "    print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play_time_by_gamers = json.dumps(\n",
    "    {\n",
    "        \"csv_file_path\": \"./Datasets/Selected/metacritic.csv\",\n",
    "        \"columns\": [\"metascore\", \"name\", \"console\"],\n",
    "        \"separator\": \",\",\n",
    "    }\n",
    ")\n",
    "\n",
    "cut_csv(play_time_by_gamers)\n",
    "\n",
    "play_time_by_gamers = json.dumps(\n",
    "    {\n",
    "        \"csv_file_path\": \"./Datasets/Selected/requirements.csv\",\n",
    "        \"columns\": [\n",
    "            \"steam_appid\",\n",
    "            \"pc_requirements\",\n",
    "            \"mac_requirements\",\n",
    "            \"linux_requirements\",\n",
    "            \"minimum\",\n",
    "        ],\n",
    "        \"separator\": \";\",\n",
    "    }\n",
    ")\n",
    "\n",
    "cut_csv(play_time_by_gamers)\n",
    "\n",
    "play_time_by_gamers = json.dumps(\n",
    "    {\n",
    "        \"csv_file_path\": \"./Datasets/Selected/all_steam.csv\",\n",
    "        \"columns\": [\n",
    "            \"game\",\n",
    "            \"link\",\n",
    "            \"release\",\n",
    "            \"rating\",\n",
    "            \"publisher\",\n",
    "            \"developer\",\n",
    "            \"detected_technologies\",\n",
    "            \"all_time_peak\",\n",
    "            \"all_time_peak_date\",\n",
    "        ],\n",
    "        \"separator\": \",\",\n",
    "    }\n",
    ")\n",
    "\n",
    "cut_csv(play_time_by_gamers)\n",
    "\n",
    "play_time_by_gamers = json.dumps(\n",
    "    {\n",
    "        \"csv_file_path\": \"./Datasets/Selected/regions.csv\",\n",
    "        \"columns\": [\n",
    "            \"Name\",\n",
    "            \"Platform\",\n",
    "            \"Year_of_Release\",\n",
    "            \"Genre\",\n",
    "            \"Publisher\",\n",
    "            \"NA_players\",\n",
    "            \"EU_players\",\n",
    "            \"JP_players\",\n",
    "            \"Other_players\",\n",
    "            \"Global_players\",\n",
    "            \"Developer\",\n",
    "            \"Rating\",\n",
    "        ],\n",
    "        \"separator\": \",\",\n",
    "    }\n",
    ")\n",
    "\n",
    "cut_csv(play_time_by_gamers)\n",
    "\n",
    "play_time_by_gamers = json.dumps(\n",
    "    {\n",
    "        \"csv_file_path\": \"./Datasets/Selected/time_to_beat.csv\",\n",
    "        \"columns\": [\n",
    "            \"achievements\",\n",
    "            \"description\",\n",
    "            \"developers\",\n",
    "            \"gfq_difficulty\",\n",
    "            \"gfq_rating\",\n",
    "            \"grnk_score\",\n",
    "            \"hltb_complete\",\n",
    "            \"hltb_single\",\n",
    "            \"igdb_score\",\n",
    "            \"igdb_single\",\n",
    "            \"igdb_uscore\",\n",
    "            \"languages\",\n",
    "            \"name\",\n",
    "            \"platforms\",\n",
    "            \"published_hltb\",\n",
    "            \"publishers\",\n",
    "            \"tags\",\n",
    "            \"voiceovers\"\n",
    "        ],\n",
    "        \"separator\": \",\",\n",
    "    }\n",
    ")\n",
    "\n",
    "cut_csv(play_time_by_gamers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all game names to common look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceToCommon(col_name):\n",
    "   for table_name in table_names:\n",
    "      df = pd.read_sql_table(table_name, engine, schema='stage')\n",
    "      df[col_name] = df[col_name].replace(r'(?<!\\d)[^\\w\\s]|[^\\w\\s](?!\\d)', ' ', regex=True)\n",
    "      df[col_name] = df[col_name].replace(r'[^\\w\\s]', '', regex=True)\n",
    "      df[col_name] = df[col_name].replace(r'\\_+', ' ', regex=True)\n",
    "      df[col_name] = df[col_name].replace(r'\\s+', ' ', regex=True)\n",
    "      df[col_name] = df[col_name].str.lower()\n",
    "      df[col_name] = df[col_name].str.strip()\n",
    "      df.to_sql(table_name, schema='stage', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "reduceToCommon('game')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all undifined with actual nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceUndefined():\n",
    "   for table_name in table_names:\n",
    "      df = pd.read_sql_table(table_name, engine, schema='stage')\n",
    "      df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "      df = df.replace(to_replace=r'\\?+', value=np.nan, regex=True)\n",
    "      df = df.replace(to_replace='null', value=np.nan)\n",
    "      df.to_sql(table_name, schema='stage', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "reduceUndefined()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert date to one type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertDate(df, col_name):\n",
    "    # Check if the column is already in the desired format ('yyyy-mm-dd')\n",
    "    already_formatted = (df[col_name].dtype == 'datetime64[ns]' and df[col_name].dt.strftime('%Y-%m-%d').unique().size == 1)\n",
    "\n",
    "    if not already_formatted:\n",
    "\n",
    "        formats = [\n",
    "            {'format': '%d.%m.%Y', 'errors': 'ignore'},\n",
    "            {\n",
    "                'format': '%Y',\n",
    "                'errors': 'coerce',\n",
    "                'post_process': lambda x: pd.to_datetime(x.astype(str) + '-01-01', errors='coerce')\n",
    "            },\n",
    "            {'format': '%d.%m.%Y %H:%M:%S', 'errors': 'ignore'}\n",
    "        ]\n",
    "\n",
    "        for format_config in formats:\n",
    "            try:\n",
    "                if 'post_process' in format_config:\n",
    "                    df[col_name] = format_config['post_process'](df[col_name])\n",
    "\n",
    "                df[col_name] = pd.to_datetime(df[col_name], format=format_config['format'], errors=format_config['errors'])\n",
    "\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    df[col_name] = pd.to_datetime(df[col_name], errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supporting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNulls(df):\n",
    "    null_values = df.isnull()\n",
    "    for column in null_values.columns.values.tolist():\n",
    "        print (null_values[column].value_counts())\n",
    "        print(\"\")\n",
    "\n",
    "def parseString(df,col_name,separator):\n",
    "    df[col_name] = df[col_name].str.split(separator)\n",
    "    df = df.explode(col_name).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def drop_nulls_overlim(df, target_columns, limit):\n",
    "    existing_columns = [col for col in target_columns if col in df.columns]\n",
    "    if existing_columns:\n",
    "        null_percentage = df[existing_columns].isnull().mean()\n",
    "        columns_to_drop = null_percentage[null_percentage >= limit].index.tolist()\n",
    "        df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "def convertToCommonScore(df, col_name, initial_scale):\n",
    "    df[col_name] = df[col_name].astype(float)\n",
    "    df[col_name] = df[col_name] / initial_scale * 100\n",
    "    np.round(df[col_name].values, decimals=1, out=df[col_name].values)\n",
    "\n",
    "def parseArraish(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(ast.literal_eval)\n",
    "    df = df.explode(col_name)\n",
    "    return df\n",
    "\n",
    "def mapToCommon(df,col_name,map):\n",
    "    df[col_name] = df[col_name].map(map)\n",
    "\n",
    "def toType(df,type,*args):\n",
    "    for arg in args:\n",
    "        df[arg] = df[arg].astype(type)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maps for reducing differences in identical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_map = {\n",
    "    'WIN':'windows',\n",
    "    'MAC':'mac',\n",
    "    'LNX':'linux',\n",
    "    'Ubuntu':'linux',\n",
    "    'WIN7':'windows',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Play time by player' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.play_time_by_player'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "#Fix data types\n",
    "df['game'] = df['game'].astype('object')\n",
    "if 'action_type' in df.columns:\n",
    "    df['action_type'] = df['action_type'].astype('object')\n",
    "df['time'] = df['time'].astype('float64')\n",
    "\n",
    "#Dicard not\n",
    "if 'action_type' in df.columns:\n",
    "    df = df[df['action_type'] == 'play']\n",
    "    df.drop('action_type', axis=1, inplace=True)\n",
    "\n",
    "#Aggregate\n",
    "df = df.groupby('game')['time'].mean().reset_index()\n",
    "\n",
    "#Round time\n",
    "df['time'] = df['time'].round(1)\n",
    "df.to_sql('play_time_by_player', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Genres' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.genres'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "#Fix data types\n",
    "df['game'] = df['game'].astype('object')\n",
    "df['developer'] = df['developer'].astype('object')\n",
    "df['genres'] = df['genres'].astype('object')\n",
    "\n",
    "#Remove summary column\n",
    "if 'summary' in df.columns:\n",
    "    df.drop('summary',axis=1,inplace=True)\n",
    " \n",
    "#Parse array into separate rows \n",
    "df = df.rename(columns={'genres':'genre'})\n",
    "df = parseArraish(df,'genre')\n",
    "\n",
    "df['developer'] = df['developer'].replace(to_replace=np.nan, value=\"['Unknown']\", regex=True)\n",
    "df = parseArraish(df,'developer')\n",
    "\n",
    "df.dropna(subset='release_date',inplace=True)\n",
    "convertDate(df,'release_date')\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.to_sql('genres', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Median play time' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.mdn_play_time'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "df = parseString(df, 'genres')\n",
    "df = parseString(df, 'platforms')\n",
    "df = parseString(df, 'developer')\n",
    "df = parseString(df, 'publisher')\n",
    "\n",
    "df[['start', 'end']] = df['owners'].str.split('-', expand=True)\n",
    "df['owners'] = (df['start'].astype(int) + df['end'].astype(int)) / 2\n",
    "df.drop(['start', 'end'], axis=1, inplace=True)\n",
    "df['owners'] = df['owners'].astype(np.int64)\n",
    "\n",
    "convertDate(df,'release_date')\n",
    "\n",
    "df = df.rename(columns={'platforms': 'os'})\n",
    "\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df = df.rename(columns={'genres':'genre'})\n",
    "df.to_sql('mdn_play_time', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Metacritic review' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.metacritic_review'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "toType(df,float,'metascore')\n",
    "\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df.to_sql('metacritic_review', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'All_steam' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.all_steam'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "df = df.dropna(subset={'all_time_peak_date'})\n",
    "df = df.rename(columns={'release':'release_date'})\n",
    "\n",
    "df['technologies'] = df['technologies'].str.split('; ')\n",
    "df = df.explode('technologies')\n",
    "df[['technology_type','technology']] = df['technologies'].str.split('.',expand=True)\n",
    "df.drop('technologies',axis=1,inplace=True)\n",
    "\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "convertDate(df,'release_date')\n",
    "convertDate(df,'all_time_peak_date')\n",
    "df['all_time_peak'] = df['all_time_peak'].astype(int) \n",
    "\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df.to_sql('all_steam', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Regions' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.regions'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "missing_percentage = df.isna().mean() * 100\n",
    "\n",
    "columns_to_check = ['rating', 'developer']\n",
    "\n",
    "drop_nulls_overlim(df,columns_to_check,0.3)\n",
    "\n",
    "df.dropna(subset='game',inplace=True)\n",
    "df.dropna(subset='publisher',inplace=True)\n",
    "df.dropna(subset='year_of_release',inplace=True)\n",
    "\n",
    "toType(df,float,'na_players','jp_players','eu_players','other_players','global_players')\n",
    "\n",
    "toType(df,float,'year_of_release')\n",
    "toType(df,int,'year_of_release')\n",
    "convertDate(df,'year_of_release')\n",
    "\n",
    "df.head()\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df = df.rename(columns={'year_of_release':'release_date'})\n",
    "df.to_sql('regions', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Time to beat' dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM stage.time_to_beat'\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "columns_to_check = ['description','tags','voiceovers','published_hltb_date']\n",
    "drop_nulls_overlim(df,columns_to_check,0.3)\n",
    "df.dropna(subset='gfq_difficulty',inplace=True)\n",
    "df.dropna(subset='hltb_single',inplace=True)\n",
    "df.dropna(subset='hltb_complete',inplace=True)\n",
    "df.dropna(subset='igdb_uscore',inplace=True)\n",
    "df.dropna(subset='gfq_rating',inplace=True)\n",
    "columns_to_check = ['grnk_score','igdb_score','igdb_single','gfq_rating','igdb_uscore']\n",
    "drop_nulls_overlim(df,columns_to_check,0.3)\n",
    "\n",
    "df.fillna({'achivements': 0}, inplace=True)\n",
    "\n",
    "convertToCommonScore(df,'gfq_rating',5)\n",
    "\n",
    "if 'platforms' in df.columns:\n",
    "    df = df.rename(columns={'platforms':'os'})\n",
    "\n",
    "df = parseString(df,'os',',')\n",
    "mapToCommon(df,'os',os_map)\n",
    "\n",
    "df = parseString(df,'languages',',')\n",
    "if 'languages' in df.columns:\n",
    "    df = df.rename(columns={'languages':'language'})\n",
    "\n",
    "df = parseString(df,'developers',',')\n",
    "if 'developers' in df.columns:\n",
    "    df = df.rename(columns={'developers':'developer'})\n",
    "\n",
    "df = parseString(df,'publishers',',')\n",
    "if 'publishers' in df.columns:\n",
    "    df = df.rename(columns={'publishers':'publisher'})\n",
    "\n",
    "toType(df,float,'hltb_single','hltb_complete','gfq_rating','igdb_uscore','achivements')\n",
    "toType(df,int,'achivements')\n",
    "\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "df.to_sql('time_to_beat', schema='stage', con=engine, if_exists='replace', index=True, index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute all above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
